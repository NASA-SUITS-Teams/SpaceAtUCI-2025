//* audio transcription service to turn bytes of audio data into a string of text
//* will be sent back to unity client to display on frontend
//* we will use a local openai whisper model since it works offline and stays on the device
//* (https://github.com/ggerganov/whisper.cpp)

import * as fs from 'fs';
import * as path from 'path';
import * as os from 'os';
import { exec } from 'child_process';
import { promisify } from 'util';

const transcriptsDir = path.join(__dirname, '../../Transcripts');

// creates a promise that will execute the whisper command
// whisper is a python command-line tool that transcribes audio
// a promise is necessary to execute a systems-level command (i.e. the python script)
// this will allow the whisper command to be executed asynchronously (in the background)
// without blocking the main thread and notifies the parent thread when it's finished
// used to preventing blocking execution of other code
const execAsync = promisify(exec);

const MODEL_SIZE = "base";

export async function transcribeAudio(
    audioData: Buffer,
    sampleRate: number = 44100,
    channels: number = 1
  ): Promise<string> {
    const wavFilePath = path.join(transcriptsDir, `${Date.now()}.wav`);

    // convert PCM buffer to WAV format
    // header is used to identify the file as a WAV file
    // whisper needs a file input to read from
    const wavHeader = createWavHeader(audioData.length, sampleRate, channels);
    const wavFile = Buffer.concat([wavHeader, audioData]);
    fs.writeFileSync(wavFilePath, wavFile); // write the WAV file to the disk so it can pass to whisper

    // whisper transcription
    const result = await execAsync(`whisper 
        ${wavFilePath} 
        --model ${MODEL_SIZE} 
        --language en 
        --output_format txt
        --output_dir ${transcriptsDir}`);

    // read the transcription from the output file
    const transcriptionPath = path.join(os.tmpdir(), `temp_audio_${Date.now()}.txt`);
    let transcription = ""; 

    // check if the file exists and only read if it does
    if (fs.existsSync(transcriptionPath)) {
        transcription = fs.readFileSync(transcriptionPath, 'utf-8');
    }

    // delete the temporary files after use
    fs.unlinkSync(wavFilePath);
    // save the transcription to the db
    fs.writeFileSync(transcriptionPath, transcription);

    return transcription;
}

// Helper function to create a WAV header
// generated by claude 3.7
function createWavHeader(
    dataLength: number, 
    sampleRate: number,
    channels: number = 1
  ): Buffer {
    const buffer = Buffer.alloc(44);
    
    // RIFF chunk descriptor
    buffer.write('RIFF', 0);
    buffer.writeUInt32LE(dataLength + 36, 4);
    buffer.write('WAVE', 8);
    
    // "fmt " sub-chunk
    buffer.write('fmt ', 12);
    buffer.writeUInt32LE(16, 16); // Subchunk1Size (16 for PCM)
    buffer.writeUInt16LE(1, 20); // AudioFormat (1 for PCM)
    buffer.writeUInt16LE(channels, 22); // NumChannels
    buffer.writeUInt32LE(sampleRate, 24); // SampleRate
    buffer.writeUInt32LE(sampleRate * channels * 2, 28); // ByteRate
    buffer.writeUInt16LE(channels * 2, 32); // BlockAlign
    buffer.writeUInt16LE(16, 34); // BitsPerSample
    
    // "data" sub-chunk
    buffer.write('data', 36);
    buffer.writeUInt32LE(dataLength, 40);
    
    return buffer;
  }